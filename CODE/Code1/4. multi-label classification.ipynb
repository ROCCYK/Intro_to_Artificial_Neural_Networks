{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b06702",
   "metadata": {},
   "source": [
    "We will use the publicly available Biomedical PubMed Multilabel Classification dataset from Kaggle https://www.kaggle.com/datasets/owaiskhan9654/pubmed-multilabel-text-classification. The dataset contain various features, but we would only use the abstractText feature with their MeSH classification (A: Anatomy, B: Organism, C: Diseases, etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e18d9",
   "metadata": {},
   "source": [
    "The above dataset shows that each paper can be classified into more than one category, the cases for Multilabel Classification. With this dataset, we can build Multilabel Classifier with Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e2040f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, max_features=2500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv('PubMed Multi Label Text Classification Dataset Processed.csv')\n",
    "df = df.drop(['Title', 'meshMajor', 'pmid', 'meshid', 'meshroot'], axis =1)\n",
    "\n",
    "X = df[\"abstractText\"]\n",
    "y = np.asarray(df[df.columns[1:]])\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=2500, max_df=0.9)\n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586b832",
   "metadata": {},
   "source": [
    "In the code above, we transform the text data into TF-IDF representation so our Scikit-Learn model can accept the training data. For now let us skip the preprocessing data steps, such as stopword removal, to simplify the tutorial.\n",
    "\n",
    "After data transformation, we split the dataset into training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a67402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "  \n",
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ee672",
   "metadata": {},
   "source": [
    "After all the preparation, we would start training our Multilabel Classifier. In Scikit-Learn, we would use the MultiOutputClassifier object to train the Multilabel Classifier model. The strategy behind this model is to train one classifier per label. Basically, each label has its own classifier.\n",
    "\n",
    "We would use Logistic Regression in this sample, and MultiOutputClassifier would extend them into all labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = MultiOutputClassifier(LogisticRegression()).fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a867c1",
   "metadata": {},
   "source": [
    "After the training, letâ€™s use the model to predict the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538decc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 1, 1, 1],\n",
       "       [0, 1, 1, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = clf.predict(X_test_tfidf)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecceacd1",
   "metadata": {},
   "source": [
    "The prediction result is an array of labels for each MeSH category. Each row represents the sentence, and each column represents the label. \n",
    "\n",
    "Lastly, we need to evaluate our Multilabel Classifier. We can use the accuracy metrics to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cc64d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score: ', accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f32df",
   "metadata": {},
   "source": [
    "Accuracy Score:  0.145\n",
    "\n",
    "The accuracy score result is 0.145, which shows that the model only could predict the exact label combination less than 14.5% of the time. However, the accuracy score contains weaknesses for a multilabel prediction evaluation. The accuracy score would need each sentence to have all the label presence in the exact position, or it would be considered wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0c1f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 0 0 0 0 0 0 0]\n",
      "[1 1 0 1 1 0 1 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(prediction[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f357f239",
   "metadata": {},
   "source": [
    "For example, the first-row prediction only differs by one label between the prediction and test data.\n",
    "\n",
    "It would be considered a wrong prediction for the accuracy score as the label combination differs. That is why our model has a low metric score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94327512",
   "metadata": {},
   "source": [
    "To mitigate this problem, we must evaluate the label prediction rather than their label combination. In this case, we can rely on Hamming Loss evaluation metric. Hamming Loss is calculated by taking a fraction of the wrong prediction with the total number of labels. Because Hamming Loss is a loss function, the lower the score is, the better (0 indicates no wrong prediction and 1 indicates all the prediction is wrong)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf1a9d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss:  0.13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "print('Hamming Loss: ', round(hamming_loss(y_test, prediction),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d76b3",
   "metadata": {},
   "source": [
    "Our Multilabel Classifier Hamming Loss model is 0.13, which means that our model would have a wrong prediction 13% of the time independently. This means each label prediction might be wrong 13% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca90b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
