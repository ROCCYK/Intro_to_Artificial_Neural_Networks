{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from https://www.kaggle.com/tongpython/cat-and-dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "##create an object of ImageDataGenerator, for augmenting train set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range=15, \n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range = 0.1,\n",
    "                                   vertical_flip=False,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode=\"reflect\")\n",
    "\n",
    "##create another object of ImageDataGenerator, for augmenting test set\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "##apply image augmentation on train set by resizing all images to 64x64 and creating batches of 32 images.\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (244,224),\n",
    "                                                 batch_size = 8)\n",
    "\n",
    "##apply image augmentation on test set by resizing all images to 64x64 and creating batches of 32 images.\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (224,244),\n",
    "                                            batch_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "#ModelCheckpoint callback saves a model at some interval. \n",
    "filepath=\"saved_models/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.h5\" #File name includes epoch and validation accuracy.\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto'\n",
    "                            )\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "#Changing learning rate\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', patience=3, factor=0.01, verbose=1, min_lr=1e-5)\n",
    "\n",
    "#CSVLogger logs epoch, acc, loss, val_acc, val_loss\n",
    "log_csv = CSVLogger('my_logs.csv', separator=',', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-6185a51cc816>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "3/2 [====================================] - ETA: -1s - loss: 1.6453 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to saved_models\\weights-improvement-01-0.50.h5\n",
      "3/2 [====================================] - 29s 10s/step - loss: 1.6453 - accuracy: 0.5000 - val_loss: 0.7037 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 0.7171 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy did not improve from 0.50000\n",
      "3/2 [====================================] - 6s 2s/step - loss: 0.7171 - accuracy: 0.5000 - val_loss: 4.7517 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 1.0369 - accuracy: 0.5000\n",
      "Epoch 00003: val_accuracy did not improve from 0.50000\n",
      "3/2 [====================================] - 7s 2s/step - loss: 1.0369 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 0.6966 - accuracy: 0.4000\n",
      "Epoch 00004: val_accuracy did not improve from 0.50000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "3/2 [====================================] - 7s 2s/step - loss: 0.6966 - accuracy: 0.4000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5000\n",
      "Epoch 00005: val_accuracy did not improve from 0.50000\n",
      "3/2 [====================================] - 6s 2s/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5000\n",
      "Epoch 00006: val_accuracy did not improve from 0.50000\n",
      "3/2 [====================================] - 7s 2s/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5000\n",
      "Epoch 00007: val_accuracy did not improve from 0.50000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "3/2 [====================================] - 7s 2s/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5000\n",
      "Epoch 00008: val_accuracy did not improve from 0.50000\n",
      "3/2 [====================================] - 6s 2s/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5000\n",
      "Epoch 00009: val_accuracy did not improve from 0.50000\n",
      "3/2 [====================================] - 7s 2s/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy did not improve from 0.50000\n",
      "3/2 [====================================] - 7s 2s/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "3/2 [====================================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5000\n",
      "Epoch 00011: val_accuracy did not improve from 0.50000\n",
      "3/2 [====================================] - 7s 2s/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "###steps_per_epoch: num of data divided by batch size\n",
    "###validation_steps: num of data divided by batch size\n",
    "history = model.fit_generator(generator=training_set,\n",
    "                         steps_per_epoch = (20/8),\n",
    "                         epochs = 20,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = (20/8),callbacks=[checkpoint,early,lr_reduce,log_csv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vgg16_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
